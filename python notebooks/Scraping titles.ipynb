{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa56aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib to get the html for a url adress\n",
    "from urllib.request import urlopen\n",
    "# Lib to search and get specifically datas of a html or xml files\n",
    "from bs4 import BeautifulSoup\n",
    "# Lib to work with dataframes\n",
    "import pandas as pd\n",
    "# Lib to open a browser and thus fully open an infinite scrolling page\n",
    "from selenium import webdriver\n",
    "# Lib to use keyboard commands\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# lib to search for page elements\n",
    "from selenium.webdriver.common.by import By\n",
    "# Lib to delay the execution\n",
    "import time\n",
    "# Lib to search a string by a partial string in a string list\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20179205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to indicate when the function of scrolling page must end\n",
    "end_points = pd.Series({'netflix' : 'To and From New York', \n",
    "              'hulu' : 'The Twilight Zone', \n",
    "              'disney-plus': 'Imagination Movers', \n",
    "              'hbo-max' : 'Zapped', \n",
    "              'amazon-prime-video' : 'Zoombies'})\n",
    "end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550ae624",
   "metadata": {},
   "outputs": [],
   "source": [
    "parental_guidelines = ['7+', '13+', '18+', '16+', 'ALL', 'ALL_AGES', 'AGES_18_', 'G', 'NC-17', 'NR', 'NOT RATED',\n",
    "      'PG', 'PG-13', 'R', 'TV-NR', 'TV-PG', 'TV-14', 'TV-G', 'TV-Y', 'TV-Y7-FV', 'TV-Y7', 'TV-MA', 'UNRATED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bc9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_check = ['min', 'Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7f1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to full scrolling of an infinite scrolling page\n",
    "def scrolling_page(streaming):\n",
    "    \n",
    "    base = 'https://flixable.com/'\n",
    "    # condition to deal with the different urls\n",
    "    if streaming == 'netflix':\n",
    "        ad = ''\n",
    "    else:\n",
    "        ad = streaming\n",
    "        \n",
    "    # open the browser   \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(base + ad)\n",
    "\n",
    "    # delay to load the page\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # get the body of the page\n",
    "    element = driver.find_element(By.TAG_NAME, \"body\")\n",
    "    \n",
    "    # variable to check when to do break condition check\n",
    "    count = 0\n",
    "\n",
    "    # loop to full open the page\n",
    "    while True:\n",
    "        element.send_keys(Keys.END)\n",
    "        time.sleep(0.5)\n",
    "        # command to go up one time to avoid loading error\n",
    "        element.send_keys(Keys.PAGE_UP)\n",
    "        \n",
    "        count += 1\n",
    "        if count == 20:\n",
    "            count = 0\n",
    "            # break condition check\n",
    "            if driver.find_elements(By.CLASS_NAME, 'card-title')[-1].text == end_points[streaming]:\n",
    "                print('Page fully open')\n",
    "                break\n",
    "    \n",
    "    # converting and saving the page\n",
    "    soup =  BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a840630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a list of titles links \n",
    "def links():\n",
    "    list_links = []\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        if '/title' in link[\"href\"]:\n",
    "                list_links.append(link[\"href\"])\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d980f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in this variable which streaming service you want to scraping\n",
    "streaming = 'netflix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a83544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running the scrolling function with the streaming chosen\n",
    "soup = scrolling_page(streaming)\n",
    "\n",
    "# Running the links function\n",
    "list_links = links()\n",
    "\n",
    "# Create the list variable to place dataset of each title\n",
    "cards = []\n",
    "\n",
    "# Create a list for the ids of possible errors \n",
    "errors = []\n",
    "\n",
    "# Create the string base for the links\n",
    "base = 'https://flixable.com'\n",
    "\n",
    "# Loop for open each link\n",
    "for i in range(0, len(list_links),2):\n",
    "\n",
    "    # Variable to store the link dataset\n",
    "    card = {}\n",
    "    \n",
    "    url = base + list_links[i]\n",
    "    try:\n",
    "        response = urlopen(url)\n",
    "    except:\n",
    "        errors.append(i)\n",
    "        continue\n",
    "    \n",
    "    # Read and parse the HTML link       \n",
    "    html = response.read()\n",
    "    html = html.decode('utf-8')\n",
    "    soup =  BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Get the title\n",
    "    card['title'] = soup.find('h1', {'class' : 'title'}).getText()\n",
    "    \n",
    "    # Create some columns for datas\n",
    "    card['release_year'] = 0\n",
    "    card['parental_guidelines'] = ' '\n",
    "    card['duration'] = ' '\n",
    "    \n",
    "    # Get the year, the parental guidelines and the duration\n",
    "    size_mr2 = len(soup.findAll('span', {'class' : 'mr-2'}))\n",
    "    for j in range(size_mr2):\n",
    "        _ = soup.findAll('span', {'class' : 'mr-2'})[j].getText()\n",
    "        if j == 0:\n",
    "            card['release_year'] = _\n",
    "\n",
    "        if _ in parental_guidelines:\n",
    "            card['parental_guidelines'] = _\n",
    "        \n",
    "        if duration_check[0] in _ or duration_check[1] in _:\n",
    "            card['duration'] = _\n",
    "    \n",
    "    # Get the genre\n",
    "    x = str(soup.findAll('a', href=True))\n",
    "    card['genre'] = []\n",
    "    genres = re.findall(r'genre/(.*?)\"', x)     \n",
    "    if len(genres) > 0:\n",
    "        for g in genres:\n",
    "            if streaming == 'netflix':\n",
    "                href = '/genre/' + g\n",
    "            else:\n",
    "                href = '/' + streaming + '/genre/' + g\n",
    "            try:\n",
    "                card['genre'].append(soup.find('a', href=href).getText())\n",
    "            except:\n",
    "                print('genre error')\n",
    "                continue\n",
    "    else:\n",
    "        card['genre'] = ' '\n",
    "\n",
    "    # Get the date_added\n",
    "    try:\n",
    "        card['date_added'] = soup.find('p', {'class' : 'mb-2'}).getText().strip().split(':')[1]\n",
    "    except:\n",
    "        card['date_added'] = ' '\n",
    "\n",
    "    # Get the average_rating\n",
    "    try:\n",
    "        average_rating = soup.h6.contents[5].getText().split('/')[0]\n",
    "        card['average_rating'] = average_rating\n",
    "    except:\n",
    "        card['average_rating'] = ' '\n",
    "\n",
    "    # Get the description\n",
    "    try:\n",
    "        card['description'] = soup.findAll('p', {'class' : 'card-description'})[0].getText().strip()\n",
    "    except:\n",
    "        card['description'] = ' '\n",
    "\n",
    "    # Join the link dataset to the list\n",
    "    cards.append(card)\n",
    "    \n",
    "    # Completion percentage indicator\n",
    "    print(round(i/len(list_links) * 100, 2), '%| indice:', i, '/', len(list_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e31fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and save as a .csv file\n",
    "df_disney_plus = pd.DataFrame(cards)\n",
    "df_disney_plus.to_csv('df_disney_plus.csv', sep=';', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31581b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and save as a .csv file\n",
    "df_hulu = pd.DataFrame(cards)\n",
    "df_hulu.to_csv('df_hulu.csv', sep=';', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c9b337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and save as a .csv file\n",
    "df_hbo_max = pd.DataFrame(cards)\n",
    "df_hbo_max.to_csv('df_hbo_max.csv', sep=';', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44f03599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and save as a .csv file\n",
    "df_prime = pd.DataFrame(cards)\n",
    "df_prime.to_csv('df_prime.csv', sep=';', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b951facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and save as a .csv file\n",
    "df_netflix = pd.DataFrame(cards)\n",
    "df_netflix.to_csv('df_netflix.csv', sep=';', index = False, encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
